{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" IMDB - Movie Writers and Directors\n",
    "\n",
    "    IMDB has a wealth of information about movies, TV shows, Video Games, etc.\n",
    "    I know more actors from my favorite movies than directors, and don't know\n",
    "    anything about the writers.\n",
    "    So I want to use IMDB's data to learn about writers and diretors.\n",
    "    First things first, I need to pare down these Giant IMDB dump files.\n",
    "    The data is available at: http://www.imdb.com/interfaces\n",
    "\"\"\"\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def trim_person_file(file_path, person_type, start_line, end_line):\n",
    "    \"\"\" This function read the IMDB database dump text file and\n",
    "        writes a tab-separated CSV file with just the writer or\n",
    "        directors of movies. The input file format is like:\n",
    "    Coen, Ethan\\t\\tA Fever in the Blood (2002)  (story \"A Fever in the Blood\")\n",
    "    \\t\\t\\tA Serious Man (2009)  (written by)  <1,1,2>\n",
    "    \\t\\t\\tBarton Fink (1991)  (written by)  <1,1,2>\n",
    "    \n",
    "    Barnes, Craig (VII)\\t\"Mike's Ma's Balls\" (2015)\n",
    "    \"\"\"\n",
    "    line_num = 0\n",
    "    person = ''\n",
    "    csv = [[person_type, 'MOVIE_TITLE', 'YEAR']]\n",
    "\n",
    "    # read the original IMDB data dump file\n",
    "    f = gzip.open(file_path, 'rb')\n",
    "    for line in f.readlines():\n",
    "        # deal with this awful IMDB headers\n",
    "        line_num += 1\n",
    "        if line_num < start_line:\n",
    "            continue\n",
    "        elif line_num > end_line:\n",
    "            break\n",
    "        elif not line.strip():\n",
    "            continue\n",
    "        \n",
    "        # finally, parse the data\n",
    "        line = line.decode('ISO-8859-1')\n",
    "        ln = line.split('\\t')\n",
    "        if line[0] != '\\t':\n",
    "            person = ln[0]\n",
    "        if ln[-1][0] == '\"' or ' (V)' in line or ' (TV)' in line or ' (VG)' in line:\n",
    "            continue\n",
    "        data = ln[-1].strip().split(' (')\n",
    "        title = data[0]\n",
    "        try:\n",
    "            year = str(int(data[1][:4]))\n",
    "        except:\n",
    "            year = ''\n",
    "        csv.append([person, title, year])\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    # write the tab-seperated writer CSV file (& gzip it)\n",
    "    fout = gzip.open(file_path.rstrip('gz') + 'trimmed.gz', 'wb')\n",
    "    for line in csv:\n",
    "        fout.write(('\\t'.join(line) + '\\n').encode('ISO-8859-1'))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Now let's create the trimmed writers and directors CSV files. \"\"\"\n",
    "\n",
    "trim_person_file('writers.list.gz', 'WRITER', 303, 4298496)\n",
    "trim_person_file('directors.list.gz', 'DIRECTOR', 236, 2757403)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trim_ratings_file(file_path, start_line, end_line):\n",
    "    \"\"\" This function read the IMDB database dump text file and\n",
    "        writes a tab-separated CSV file with just the weighted\n",
    "        user rating of each movie. The input file format is like:\n",
    "          1000000102      62   6.2  \"#1 Single\" (2006)\n",
    "          1.0..01103      14   7.1  \"#7DaysLater\" (2013)\n",
    "          2....0.013      11   6.8  \"#Bikerlive\" (2014)\n",
    "          2.01..3.01      13   5.5  \"#ByMySide\" (2012)\n",
    "          0000011101      24   6.5  The Big Leap (2013)\n",
    "          0000001222  491417   8.2  The Big Lebowski (1998)\n",
    "    \"\"\"\n",
    "    line_num = 0\n",
    "    person = ''\n",
    "    csv = [['VOTES', 'RANK', 'MOVIE_TITLE', 'YEAR']]\n",
    "\n",
    "    # read the original IMDB data dump file\n",
    "    f = gzip.open(file_path, 'rb')\n",
    "    for line in f.readlines():\n",
    "        # deal with this awful IMDB headers\n",
    "        line_num += 1\n",
    "        if line_num < start_line:\n",
    "            continue\n",
    "        elif line_num > end_line:\n",
    "            break\n",
    "        \n",
    "        # finally, parse the data\n",
    "        line = line.decode('ISO-8859-1')\n",
    "        if line[32] == '\"':\n",
    "            # this is a TV show, skip\n",
    "            continue\n",
    "        elif ' (V)' in line or ' (TV)' in line:\n",
    "            # this isn't a real movie\n",
    "            continue\n",
    "        votes = line[16:25].strip()\n",
    "        rank = line[25:30].strip()\n",
    "        try:\n",
    "            dummy = int(votes)\n",
    "            dummy = float(rank)\n",
    "        except:\n",
    "            print(votes, rank)\n",
    "            print(line)\n",
    "            return\n",
    "        movie = line[31:].strip().split(' (')\n",
    "        movie_title = movie[0]\n",
    "        try:\n",
    "            year = str(int(movie[1][:4]))\n",
    "        except:\n",
    "            year = ''\n",
    "        csv.append([votes, rank, movie_title, year])\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    # write the tab-seperated writer CSV file (& gzip it)\n",
    "    fout = gzip.open(file_path.rstrip('gz') + 'trimmed.gz', 'wb')\n",
    "    for line in csv:\n",
    "        fout.write(('\\t'.join(line) + '\\n').encode('ISO-8859-1'))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Now let's create the trimmed movie ratins file. \"\"\"\n",
    "\n",
    "trim_ratings_file('ratings.list.gz', 297, 667884)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "notes = \"\"\" It is probably interesting to note that when IMDB\n",
    "            comes up with their official \"top 250\" movies, they\n",
    "            use this formula:\n",
    "\n",
    "            TOP 250 MOVIES (25000+ VOTES)\n",
    "            \n",
    "            The formula used to calculate the top 250 movies is:\n",
    "            \n",
    "            weighted rank = (v/(v+k))*X + (k/(v+k))*C\n",
    "\n",
    "            where:\n",
    "\n",
    "            X = average for the movie (mean)\n",
    "            v = number of votes for the movie\n",
    "            k = minimum votes required to be listed in the top 250 (currently 25000)\n",
    "            C = the mean vote across the whole report (currently 6.90)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
